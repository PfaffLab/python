#!/usr/bin/python
#==============================================================================
# asi-indexG-quant-from-junctions.py
#
# Shawn Driscoll
# 20160915
#
# Gene Expression Laboratory, Pfaff
# Salk Institute for Biological Studies
#
# This file quantifies alt-events from junction found in genome alignments. 
# the indexes are built by asi-build-indexG.py using the two tsv files 
# generated by that script.
#==============================================================================

import sys, argparse, math, re
from os.path import isfile, expanduser

# from igraph import *
# from subprocess import Popen
# from random import gauss, random, sample
# from scipy.stats import norm
import numpy as np
# import numpy.random as npr

# R support
# import rpy2.robjects as robjects
# r = robjects.r

#==============================================================================
# globals
#==============================================================================

HOME = expanduser("~")

#==============================================================================
# main
#==============================================================================

def main(args):

	# variables
	quant = {}
	rres = 0
	total_depth = 0

	# load junctions
	sys.stderr.write("loading junctions ({})\n".format(args.junctions))
	djuncs = parse_junctions(args.junctions, args.s, args.b, args.c)

	# load paths and assign hits from junctions
	sys.stderr.write("loading path to junction table\n")
	dpaths = load_paths(args.intron_index)

	# load event annotation and produce output
	sys.stderr.write("loading event index and generating output\n")
	rres = quantify_events(args.event_index, dpaths, djuncs)

	return 0

def quantify_events(f, dpaths, djuncs, shift=0):
	#
	# variables
	lheader = []
	szl = ""
	aln = []
	cidx = -1
	# 
	# keep mean count and the associated uncertainty
	countA = [0, 0]
	countB = [0, 0]

	#
	# open event index
	fin = open(f, "r")
	#
	# read in the header
	lheader = fin.readline().strip().split("\t")

	#
	# find column index of first path id
	for i in range(len(lheader)):
		if lheader[i]=="path_id.A":
			cidx = i
			break

	# fail
	if cidx < 0:
		sys.stderr.write("Error: failed to find path_id.A column header in event index\n")
		fin.close()
		return 1

	lheader += ["mean.A", "mean.B", "psi", "var"]
	print "\t".join(lheader)

	#
	# continue...
	for szl in fin:
		aln = szl.strip().split("\t")

		#
		# retained introns will work a little differently
		if aln[1] != "RI":

			pidA = aln[cidx]
			pidB = aln[cidx+1]
			
			if pidA in dpaths:
				iidA = dpaths[pidA]
			else:
				sys.stderr.write("Failed to find path {} in the paths table\n".format(pidA))
				return 1

			if pidB in dpaths:	
				iidB = dpaths[pidB]
			else:
				sys.stderr.write("Failed to find path {} in the paths table\n".format(pidB))
				return 1

			# 
			# keep mean count and the associated uncertainty
			countsA = []
			countsB = []
			for iid in iidA:
				if iid in djuncs:
					countsA.append(djuncs[iid]['count'])

			for iid in iidB:
				if iid in djuncs:
					countsB.append(djuncs[iid]['count'])
			
#			countsA = [djuncs[iid]['count'] for iid in iidA]
#			countsB = [djuncs[iid]['count'] for iid in iidB]

			if sum(countsA) > 0 or sum(countsB) > 0:
				aln = aln + [safe_mean(countsA), safe_mean(countsB)]
				aln = aln + psi_from_counts(countsA, countsB)
			else:
				aln = aln + [0, 0, -1, -1]
				
			print "\t".join(map(str, aln))

		else:
			# we have a retained intro situation. the second path is the one with the 
			# intron
			pidB = aln[cidx+1]
			if pidB in dpaths:
				iidB = dpaths[pidB]
			else:
				sys.stderr.write("Failed to find path {} in the paths table\n".format(pidB))
				return 1

			if len(iidB) > 1:
				sys.stderr.write("Warning: found RI event with more than 1 path! " + "|".join(iidB) + "\n")
				aln = aln + [0, 0, -1, -1]
				print "\t".join(map(str, aln))
				continue

			iid = iidB[0]

			if iid not in djuncs:
				# this junction doesn't exist
				sys.stderr.write("Warning: RI junction does not exist! " + "|".join([iid, pidB]) + "\n")
				aln = aln + [0, 0, -1, -1]
				print "\t".join(map(str, aln))
				continue

			countsA = djuncs[iid]['ovl']
			countsB = [djuncs[iid]['count']]

			# 
			# keep mean count and the associated uncertainty
#			countsA = djuncs[iid]['ovl']
#			countsB = [djuncs[iid]['count'] for iid in iidB]

			aln = aln + [safe_mean(countsA), safe_mean(countsB)]
			aln = aln + psi_from_counts(countsA, countsB)
			print "\t".join(map(str, aln))


	fin.close()

	return 0


#
# calculates psi value (a/(a+b)) and the associated psi variance
# based on count variance and poisson noise at the counts
def psi_from_counts(a, b):

	#
	# calculate means and variances
	mu_a = 0
	mu_b = 0
	var_a = 0
	var_b = 0
	mu_psi = -1
	var_psi = -1

	if len(a) > 0:
		mu_a = np.mean(a)
		var_a = mu_a+1
	
	if len(b) > 0:
		mu_b = np.mean(b)
		var_b = mu_b+1

	#
	# if a or b have more than a single value we can add in the variance
	# of the counts involved
	if len(a) > 1:
		var_a += np.std(a, ddof=1)**2

	if len(b) > 1:
		var_b += np.std(b, ddof=1)**2

	if mu_a > 0 and mu_b > 0:
		mu_psi = mu_a/(mu_a+mu_b)
	else:
		if mu_a > 0:
			mu_psi = 1
		elif mu_b > 0:
			mu_psi = 0
		else:
			mu_psi = -1

	# 
	# variace of psi is based on the method of moments for a function of 2 variables
	# which is Var(psi) = (dpsi/da)^2 * Var(a) + (dpsi/db)^2 * Var(b) + [assuming a and b are uncorrelated]
	if mu_a > 0 or mu_b > 0:
		dpsi_da = mu_b/(mu_a+mu_b)**2
		dpsi_db = -mu_a/(mu_a+mu_b)**2
		var_psi = (dpsi_da**2 * var_a) + (dpsi_db**2 * var_b)

	return [mu_psi, var_psi]

def safe_mean(x):

	n = len(x)

	if n==0:
		return 0
	
	return np.mean(x)

def load_paths(f):
	#
	# dict to hold path results
	dout = {}
	#
	# open input file
	fin = open(f, "r")
	for szl in fin:
		aln = szl.strip().split("\t")
		lints = aln[1].split(",")
		#
		# put in a list of the introns associated with this path
		dout[aln[0]] = lints

	fin.close()
	return dout


def parse_junctions(f, skip, bed, col):
	#
	# dict to hold junctions keyed by their intron position info
	djcount = {}
	# if the input is a juncdb file and the header contains both 'acc_ovl' and 'donor_ovl'
	# then we can calculate the retention of introns that have the RI type in the event
	has_theta = False
	cidx_do = -1
	cidx_ao = -1

	#
	# open input file
	fin = open(f, "r")
	#
	# keep a counter
	i = 0
	if skip > 0:
		while i < skip:
			szl = fin.readline()
			r = re.search("acc_ovl", szl)
			if r:
				aln = szl.strip().split("\t")
				has_theta = True
				# get index of 'donor_ovl' and 'acc_ovl'
				for j in range(len(aln)):
					if aln[j] == "donor_ovl":
						cidx_do = j
					elif aln[j] == "acc_ovl":
						cidx_ao = j

			i += 1
	#
	# loop through the file and parse out the junction counts
	for szl in fin:
		aln = szl.strip().split("\t")
		if bed: 
			btmp = map(int, aln[10].split(","))
			aln[1] = int(aln[1])+btmp[0]+1
			aln[2] = int(aln[2])-btmp[1]

		jid = "{}:{}-{}".format(aln[0], aln[1], aln[2])
		djcount[jid] = dict(count=0, ovl=[0, 0])

		if bed:
			djcount[jid]['count'] = float(aln[4])
		else:
			djcount[jid]['count'] = float(aln[col])

		if has_theta:
			djcount[jid]['ovl'][0] = float(aln[cidx_do])
			djcount[jid]['ovl'][1] = float(aln[cidx_ao])

	fin.close()
	return djcount	


def parse_index(f, dquant):

	szl = ""
	aln = []
	aln0 = []
	aheader = []

	fin = open(f, "r")
	# keep header
	aheader = fin.readline().strip().split("\t")
	aheader = aheader + ["tpm.A", "tpm.B", "psi"]
	print "\t".join(aheader)

	# parse the rest of the file
	for szl in fin:
		aln0 = szl.strip().split("\t")
		aln = process_event(aln0, dquant)
		print "\t".join(map(str, aln))

	fin.close()

	return 0


#==============================================================================
# entry point
#==============================================================================


parser = argparse.ArgumentParser(description="Quantify AE events from either junctions (in bed format) or a psi/theta result from 'bam2juncs' or something similar. Default is output of 'bam2juncs'.")
parser.add_argument('intron_index', type=str, help="The TSV index of introns from asi-build-indexG.py")
parser.add_argument('event_index', type=str, help="The TSV index of events from asi-build-indexG.py")
parser.add_argument('junctions', type=str, 
	help="Either junctions from alignments or the juncdb type quantification")
parser.add_argument('-b', action="store_const", const=True, default=False, 
	help="Input junctions are in BED format having values for overlap width in column 11")
parser.add_argument('-s', action="store", type=int, default=0, 
	help="Skip this many lines from the top of the junctions file [0]")
parser.add_argument('-c', action="store", type=int, default=3, 
	help="Zero based column index to find the junction counts. Classic bed format would have this in colun 4. [3]")

args = parser.parse_args()

if __name__ == "__main__":

	try:
		sys.exit(main(args))
	except KeyboardInterrupt:
		sys.stderr.write("\nkilled it\n")

